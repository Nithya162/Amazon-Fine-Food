{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e85a51db",
      "metadata": {
        "id": "e85a51db"
      },
      "outputs": [],
      "source": [
        "# This is a special command used in Jupyter notebooks to display Matplotlib plots directly within the notebook.\n",
        "%matplotlib inline\n",
        "\n",
        "# Importing required libraries\n",
        "import sqlite3  # For working with SQL databases\n",
        "import pandas as pd  # For data manipulation and analysis\n",
        "import numpy as np  # For numerical computing\n",
        "\n",
        "# Natural Language Processing toolkit\n",
        "import nltk\n",
        "from nltk.stem.porter import PorterStemmer  # For stemming\n",
        "\n",
        "# String module\n",
        "import string\n",
        "\n",
        "# Plotting libraries\n",
        "import matplotlib.pyplot as plt  # For creating visualizations\n",
        "import seaborn as sns  # For enhanced statistical data visualizations\n",
        "\n",
        "# Machine learning libraries from scikit-learn\n",
        "from sklearn.feature_extraction.text import TfidfTransformer  # For TF-IDF transformation\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer  # For converting text to numerical data\n",
        "from sklearn.metrics import confusion_matrix  # For creating confusion matrices\n",
        "from sklearn import metrics  # For evaluating machine learning models\n",
        "from sklearn.metrics import roc_curve, auc  # For plotting ROC curve and calculating AUC\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "842d6fae",
      "metadata": {
        "id": "842d6fae"
      },
      "outputs": [],
      "source": [
        "con = sqlite3.connect('C:/Users/nithy/OneDrive/Desktop/Amazon_fine_food/database.sqlite')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "44fdffd8",
      "metadata": {
        "id": "44fdffd8"
      },
      "outputs": [],
      "source": [
        "# load my data using sql and pandas\n",
        "# not taking those reviews with score = 3\n",
        "# run sql command using the connection , con\n",
        "filtered_data = pd.read_sql_query(\"\"\"\n",
        "SELECT *\n",
        "FROM Reviews\n",
        "WHERE Score != 3\n",
        "\"\"\" , con)\n",
        "\n",
        "def partition(x):\n",
        "    if x<3:\n",
        "        return 'negative'\n",
        "    return 'positive'\n",
        "\n",
        "actualScore = filtered_data['Score']\n",
        "positivenegative = actualScore.map(partition)\n",
        "filtered_data['Score'] = positivenegative\n",
        "\n",
        "\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8c97f0d1",
      "metadata": {
        "scrolled": true,
        "id": "8c97f0d1",
        "outputId": "f2998f1e-b771-4038-af2f-1ff2cc539cbc"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Id</th>\n",
              "      <th>ProductId</th>\n",
              "      <th>UserId</th>\n",
              "      <th>ProfileName</th>\n",
              "      <th>HelpfulnessNumerator</th>\n",
              "      <th>HelpfulnessDenominator</th>\n",
              "      <th>Score</th>\n",
              "      <th>Time</th>\n",
              "      <th>Summary</th>\n",
              "      <th>Text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>B001E4KFG0</td>\n",
              "      <td>A3SGXH7AUHU8GW</td>\n",
              "      <td>delmartian</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>positive</td>\n",
              "      <td>1303862400</td>\n",
              "      <td>Good Quality Dog Food</td>\n",
              "      <td>I have bought several of the Vitality canned d...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>B00813GRG4</td>\n",
              "      <td>A1D87F6ZCVE5NK</td>\n",
              "      <td>dll pa</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>negative</td>\n",
              "      <td>1346976000</td>\n",
              "      <td>Not as Advertised</td>\n",
              "      <td>Product arrived labeled as Jumbo Salted Peanut...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>B000LQOCH0</td>\n",
              "      <td>ABXLMWJIXXAIN</td>\n",
              "      <td>Natalia Corres \"Natalia Corres\"</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>positive</td>\n",
              "      <td>1219017600</td>\n",
              "      <td>\"Delight\" says it all</td>\n",
              "      <td>This is a confection that has been around a fe...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>B000UA0QIQ</td>\n",
              "      <td>A395BORC6FGVXV</td>\n",
              "      <td>Karl</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>negative</td>\n",
              "      <td>1307923200</td>\n",
              "      <td>Cough Medicine</td>\n",
              "      <td>If you are looking for the secret ingredient i...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>B006K2ZZ7K</td>\n",
              "      <td>A1UQRSCLF8GW1T</td>\n",
              "      <td>Michael D. Bigham \"M. Wassir\"</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>positive</td>\n",
              "      <td>1350777600</td>\n",
              "      <td>Great taffy</td>\n",
              "      <td>Great taffy at a great price.  There was a wid...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Id   ProductId          UserId                      ProfileName  \\\n",
              "0   1  B001E4KFG0  A3SGXH7AUHU8GW                       delmartian   \n",
              "1   2  B00813GRG4  A1D87F6ZCVE5NK                           dll pa   \n",
              "2   3  B000LQOCH0   ABXLMWJIXXAIN  Natalia Corres \"Natalia Corres\"   \n",
              "3   4  B000UA0QIQ  A395BORC6FGVXV                             Karl   \n",
              "4   5  B006K2ZZ7K  A1UQRSCLF8GW1T    Michael D. Bigham \"M. Wassir\"   \n",
              "\n",
              "   HelpfulnessNumerator  HelpfulnessDenominator     Score        Time  \\\n",
              "0                     1                       1  positive  1303862400   \n",
              "1                     0                       0  negative  1346976000   \n",
              "2                     1                       1  positive  1219017600   \n",
              "3                     3                       3  negative  1307923200   \n",
              "4                     0                       0  positive  1350777600   \n",
              "\n",
              "                 Summary                                               Text  \n",
              "0  Good Quality Dog Food  I have bought several of the Vitality canned d...  \n",
              "1      Not as Advertised  Product arrived labeled as Jumbo Salted Peanut...  \n",
              "2  \"Delight\" says it all  This is a confection that has been around a fe...  \n",
              "3         Cough Medicine  If you are looking for the secret ingredient i...  \n",
              "4            Great taffy  Great taffy at a great price.  There was a wid...  "
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "filtered_data.shape\n",
        "filtered_data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "240acc1f",
      "metadata": {
        "id": "240acc1f",
        "outputId": "1f8cf3d2-2835-4b19-ccef-bdfe4cb581b0"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Id</th>\n",
              "      <th>ProductId</th>\n",
              "      <th>UserId</th>\n",
              "      <th>ProfileName</th>\n",
              "      <th>HelpfulnessNumerator</th>\n",
              "      <th>HelpfulnessDenominator</th>\n",
              "      <th>Score</th>\n",
              "      <th>Time</th>\n",
              "      <th>Summary</th>\n",
              "      <th>Text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>78445</td>\n",
              "      <td>B000HDL1RQ</td>\n",
              "      <td>AR5J8UI46CURR</td>\n",
              "      <td>Geetha Krishnan</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "      <td>1199577600</td>\n",
              "      <td>LOACKER QUADRATINI VANILLA WAFERS</td>\n",
              "      <td>DELICIOUS WAFERS. I FIND THAT EUROPEAN WAFERS ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>138317</td>\n",
              "      <td>B000HDOPYC</td>\n",
              "      <td>AR5J8UI46CURR</td>\n",
              "      <td>Geetha Krishnan</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "      <td>1199577600</td>\n",
              "      <td>LOACKER QUADRATINI VANILLA WAFERS</td>\n",
              "      <td>DELICIOUS WAFERS. I FIND THAT EUROPEAN WAFERS ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>138277</td>\n",
              "      <td>B000HDOPYM</td>\n",
              "      <td>AR5J8UI46CURR</td>\n",
              "      <td>Geetha Krishnan</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "      <td>1199577600</td>\n",
              "      <td>LOACKER QUADRATINI VANILLA WAFERS</td>\n",
              "      <td>DELICIOUS WAFERS. I FIND THAT EUROPEAN WAFERS ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>73791</td>\n",
              "      <td>B000HDOPZG</td>\n",
              "      <td>AR5J8UI46CURR</td>\n",
              "      <td>Geetha Krishnan</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "      <td>1199577600</td>\n",
              "      <td>LOACKER QUADRATINI VANILLA WAFERS</td>\n",
              "      <td>DELICIOUS WAFERS. I FIND THAT EUROPEAN WAFERS ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>155049</td>\n",
              "      <td>B000PAQ75C</td>\n",
              "      <td>AR5J8UI46CURR</td>\n",
              "      <td>Geetha Krishnan</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "      <td>1199577600</td>\n",
              "      <td>LOACKER QUADRATINI VANILLA WAFERS</td>\n",
              "      <td>DELICIOUS WAFERS. I FIND THAT EUROPEAN WAFERS ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       Id   ProductId         UserId      ProfileName  HelpfulnessNumerator  \\\n",
              "0   78445  B000HDL1RQ  AR5J8UI46CURR  Geetha Krishnan                     2   \n",
              "1  138317  B000HDOPYC  AR5J8UI46CURR  Geetha Krishnan                     2   \n",
              "2  138277  B000HDOPYM  AR5J8UI46CURR  Geetha Krishnan                     2   \n",
              "3   73791  B000HDOPZG  AR5J8UI46CURR  Geetha Krishnan                     2   \n",
              "4  155049  B000PAQ75C  AR5J8UI46CURR  Geetha Krishnan                     2   \n",
              "\n",
              "   HelpfulnessDenominator  Score        Time  \\\n",
              "0                       2      5  1199577600   \n",
              "1                       2      5  1199577600   \n",
              "2                       2      5  1199577600   \n",
              "3                       2      5  1199577600   \n",
              "4                       2      5  1199577600   \n",
              "\n",
              "                             Summary  \\\n",
              "0  LOACKER QUADRATINI VANILLA WAFERS   \n",
              "1  LOACKER QUADRATINI VANILLA WAFERS   \n",
              "2  LOACKER QUADRATINI VANILLA WAFERS   \n",
              "3  LOACKER QUADRATINI VANILLA WAFERS   \n",
              "4  LOACKER QUADRATINI VANILLA WAFERS   \n",
              "\n",
              "                                                Text  \n",
              "0  DELICIOUS WAFERS. I FIND THAT EUROPEAN WAFERS ...  \n",
              "1  DELICIOUS WAFERS. I FIND THAT EUROPEAN WAFERS ...  \n",
              "2  DELICIOUS WAFERS. I FIND THAT EUROPEAN WAFERS ...  \n",
              "3  DELICIOUS WAFERS. I FIND THAT EUROPEAN WAFERS ...  \n",
              "4  DELICIOUS WAFERS. I FIND THAT EUROPEAN WAFERS ...  "
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Data cleaning or DEDUPLICATION\n",
        "# display is used to display the table\n",
        "# condition is used to print\n",
        "display = pd.read_sql_query(\"\"\"\n",
        "SELECT *\n",
        "FROM Reviews\n",
        "WHERE Score!=3 AND UserId = \"AR5J8UI46CURR\"\n",
        "ORDER BY ProductID\n",
        "\"\"\", con)\n",
        "display\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "511762aa",
      "metadata": {
        "id": "511762aa"
      },
      "outputs": [],
      "source": [
        "#sorting the data according to product Id\n",
        "sorted_data = filtered_data.sort_values('ProductId', axis = 0, ascending = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "81da1148",
      "metadata": {
        "id": "81da1148",
        "outputId": "91ba2671-3a43-44ba-afd8-705d3d9bd438"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(364173, 10)"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "final = sorted_data.drop_duplicates(subset={\"UserId\",\"ProfileName\",\"Time\",\"Text\"} , keep='first' , inplace=False)\n",
        "final.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "be75014a",
      "metadata": {
        "id": "be75014a",
        "outputId": "d06c909a-d511-4b6c-a704-40d2bbfa3a75"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "69.25890143662969"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# check how much % of data still remains\n",
        "(final['Id'].size*1.0)/(filtered_data['Id'].size*1.0)*100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2ae5d3ce",
      "metadata": {
        "id": "2ae5d3ce",
        "outputId": "3cca2c06-030e-43a2-b5ef-a85ca2f7dec1"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Id</th>\n",
              "      <th>ProductId</th>\n",
              "      <th>UserId</th>\n",
              "      <th>ProfileName</th>\n",
              "      <th>HelpfulnessNumerator</th>\n",
              "      <th>HelpfulnessDenominator</th>\n",
              "      <th>Score</th>\n",
              "      <th>Time</th>\n",
              "      <th>Summary</th>\n",
              "      <th>Text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>64422</td>\n",
              "      <td>B000MIDROQ</td>\n",
              "      <td>A161DK06JJMCYF</td>\n",
              "      <td>J. E. Stephens \"Jeanne\"</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>1224892800</td>\n",
              "      <td>Bought This for My Son at College</td>\n",
              "      <td>My son loves spaghetti so I didn't hesitate or...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>44737</td>\n",
              "      <td>B001EQ55RW</td>\n",
              "      <td>A2V0I904FH7ABY</td>\n",
              "      <td>Ram</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>1212883200</td>\n",
              "      <td>Pure cocoa taste with crunchy almonds inside</td>\n",
              "      <td>It was almost a 'love at first bite' - the per...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      Id   ProductId          UserId              ProfileName  \\\n",
              "0  64422  B000MIDROQ  A161DK06JJMCYF  J. E. Stephens \"Jeanne\"   \n",
              "1  44737  B001EQ55RW  A2V0I904FH7ABY                      Ram   \n",
              "\n",
              "   HelpfulnessNumerator  HelpfulnessDenominator  Score        Time  \\\n",
              "0                     3                       1      5  1224892800   \n",
              "1                     3                       2      4  1212883200   \n",
              "\n",
              "                                        Summary  \\\n",
              "0             Bought This for My Son at College   \n",
              "1  Pure cocoa taste with crunchy almonds inside   \n",
              "\n",
              "                                                Text  \n",
              "0  My son loves spaghetti so I didn't hesitate or...  \n",
              "1  It was almost a 'love at first bite' - the per...  "
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#n<d\n",
        "display = pd.read_sql_query(\"\"\"\n",
        "SELECT *\n",
        "FROM Reviews\n",
        "WHERE Score !=3 AND Id=44737 OR Id = 64422\n",
        "ORDER BY ProductId\n",
        "\"\"\" , con)\n",
        "display"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a99c387d",
      "metadata": {
        "id": "a99c387d"
      },
      "outputs": [],
      "source": [
        "final=final[final.HelpfulnessNumerator<=final.HelpfulnessDenominator]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a84fdbcb",
      "metadata": {
        "id": "a84fdbcb",
        "outputId": "50373537-7189-432e-9631-9f74646ecc0b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(364171, 10)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "Score\n",
              "positive    307061\n",
              "negative     57110\n",
              "Name: count, dtype: int64"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "print(final.shape)\n",
        "final['Score'].value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "062bbe29",
      "metadata": {
        "id": "062bbe29"
      },
      "source": [
        "# Text Pre processing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "77a14020",
      "metadata": {
        "id": "77a14020",
        "outputId": "f3634e31-ce4d-402f-b303-4d0df77c14a0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "6\n",
            "I set aside at least an hour each day to read to my son (3 y/o). At this point, I consider myself a connoisseur of children's books and this is one of the best. Santa Clause put this under the tree. Since then, we've read it perpetually and he loves it.<br /><br />First, this book taught him the months of the year.<br /><br />Second, it's a pleasure to read. Well suited to 1.5 y/o old to 4+.<br /><br />Very few children's books are worth owning. Most should be borrowed from the library. This book, however, deserves a permanent spot on your shelf. Sendak's best.\n"
          ]
        }
      ],
      "source": [
        "import re\n",
        "i =0;\n",
        "for sent in final['Text'].values:\n",
        "    if(len(re.findall('<.*?>',sent))):\n",
        "        print(i)\n",
        "        print(sent)\n",
        "        break;\n",
        "    i+= 1;"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "606c2770",
      "metadata": {
        "id": "606c2770",
        "outputId": "76a4f868-1b16-43c1-9587-8831282ee45b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'my', 'each', 'have', 'up', \"isn't\", 'because', 'such', \"shouldn't\", 'why', 'or', 'his', 'him', 'do', 'by', 'against', 'themselves', 'o', 'theirs', 'above', 'has', 'hers', 'who', 'its', 'did', 'over', 'be', 'there', 'aren', 'm', \"haven't\", \"wasn't\", 'both', 'through', 'wasn', 'am', 'for', 'own', \"mightn't\", 'during', 'your', 'y', 'when', 'that', 'few', 'ourselves', 'yourself', 'haven', \"that'll\", 'mightn', 'further', 'myself', 'their', \"you'd\", 'wouldn', 'as', 'was', 'me', \"aren't\", 'himself', 'the', 'under', 'll', \"hasn't\", \"don't\", 'yourselves', 'herself', 'should', 'itself', 'whom', 'ma', 'is', 'in', 'it', \"it's\", 'you', 'isn', 'to', 'mustn', 'at', 'ain', 'where', 'off', 'needn', 'ours', 'any', 'after', 'most', 'what', 'only', 'had', 'these', 'which', 'will', \"you're\", 'yours', 'her', 'then', 'other', 'they', 'down', 'd', 'nor', 'couldn', \"shan't\", 'but', 'again', \"couldn't\", 'on', 'a', \"she's\", 'now', 'once', 'until', \"doesn't\", 'hadn', 'more', \"mustn't\", \"hadn't\", 'hasn', 'are', \"won't\", 'out', 'no', 'all', 'just', 'while', 'were', 'this', 'being', 'shan', 'having', 'doesn', 'before', 'he', 'we', 'won', 'how', 'about', 'so', 'if', 'same', \"needn't\", 'and', 'them', 'does', 'doing', \"you've\", 'can', 'between', \"weren't\", 'from', 'some', \"wouldn't\", \"should've\", 'than', 'weren', 'those', 've', 'with', 'not', 's', 't', 'she', 'i', 'here', 'shouldn', \"you'll\", 're', 'below', 'too', 'didn', 'very', 'of', 'our', 'been', \"didn't\", 'don', 'an', 'into'}\n",
            "*****************************\n",
            "tasti\n"
          ]
        }
      ],
      "source": [
        "import re\n",
        "import string\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.stem.wordnet import WordNetLemmatizer\n",
        "\n",
        "stop = set(stopwords.words('english'))\n",
        "sno = nltk.stem.SnowballStemmer('english')\n",
        "\n",
        "def cleanhtml(sentence):\n",
        "    cleanr = re.compile('<.*?')\n",
        "    cleantext = re.sub(cleanr, ' ', sentence)\n",
        "    return cleantext\n",
        "def cleanpunc(sentence):\n",
        "    cleaned = re.sub(r'[?|!|\\'|\"|#]',r'',sentence)\n",
        "    cleaned = re.sub(r'[.|,|)|(|\\|/]',r' ',cleaned)\n",
        "    return cleaned\n",
        "print(stop)\n",
        "print('*****************************')\n",
        "print(sno.stem('tasty'))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a88d3fc3",
      "metadata": {
        "id": "a88d3fc3"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Initialize lists\n",
        "all_positive_words = []\n",
        "all_negative_words = []\n",
        "final_string = []\n",
        "\n",
        "# Convert stop words list to a set for faster membership checking\n",
        "stop_set = set(stop)\n",
        "\n",
        "# Use pandas vectorized methods to clean and tokenize text data\n",
        "final['cleaned_text'] = final['Text'].apply(cleanhtml)\n",
        "final['cleaned_words'] = final['cleaned_text'].apply(lambda x: [word for word in cleanpunc(x).split() if len(word) > 2 and word.isalpha() and word.lower() not in stop_set])\n",
        "\n",
        "# Cache stemmed words to avoid repeated computations\n",
        "stem_cache = {}\n",
        "\n",
        "def get_stemmed_word(word):\n",
        "    if word not in stem_cache:\n",
        "        stem_cache[word] = sno.stem(word).encode('utf-8')\n",
        "    return stem_cache[word]\n",
        "\n",
        "# Vectorized processing\n",
        "def process_row(row):\n",
        "    filtered_sentence = []\n",
        "    for word in row['cleaned_words']:\n",
        "        stemmed_word = get_stemmed_word(word.lower())\n",
        "        filtered_sentence.append(stemmed_word)\n",
        "\n",
        "        if row['Score'] == 'positive':\n",
        "            all_positive_words.append(stemmed_word)\n",
        "        elif row['Score'] == 'negative':\n",
        "            all_negative_words.append(stemmed_word)\n",
        "\n",
        "    return b\" \".join(filtered_sentence)\n",
        "\n",
        "# Apply the processing function to each row in the DataFrame\n",
        "final['final_string'] = final.apply(process_row, axis=1)\n",
        "\n",
        "# Convert the resulting Series to a list\n",
        "final_string = final['final_string'].tolist()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "caf86c62",
      "metadata": {
        "id": "caf86c62"
      },
      "outputs": [],
      "source": [
        "final['CleanedText'] = final_string"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f6dbe50e",
      "metadata": {
        "scrolled": true,
        "id": "f6dbe50e",
        "outputId": "4a277ffa-4574-478d-d08b-2cdeef852e67"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Id                         int64\n",
            "ProductId                 object\n",
            "UserId                    object\n",
            "ProfileName               object\n",
            "HelpfulnessNumerator       int64\n",
            "HelpfulnessDenominator     int64\n",
            "Score                     object\n",
            "Time                       int64\n",
            "Summary                   object\n",
            "Text                      object\n",
            "cleaned_text              object\n",
            "cleaned_words             object\n",
            "final_string              object\n",
            "CleanedText               object\n",
            "dtype: object\n"
          ]
        }
      ],
      "source": [
        "print(final.dtypes)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a68711e0",
      "metadata": {
        "id": "a68711e0"
      },
      "source": [
        "# Bag of words(BoW)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9451446a",
      "metadata": {
        "id": "9451446a"
      },
      "outputs": [],
      "source": [
        "# for each row ri we have to get a vector vi\n",
        "# scikit learn is the most popular machine learning library\n",
        "# CountVectorizer is a function / class\n",
        "count_vect = CountVectorizer()\n",
        "final_counts = count_vect.fit_transform(final['Text'].values)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1c7555cd",
      "metadata": {
        "id": "1c7555cd",
        "outputId": "c637ec0f-b1d1-4267-cdb1-1e682f1edc32"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "scipy.sparse._csr.csr_matrix"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "type(final_counts)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "59855ea4",
      "metadata": {
        "id": "59855ea4",
        "outputId": "3b5a8210-933d-431d-c175-31096e44cbcf"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(364171, 115281)"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "final_counts.get_shape()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f714409d",
      "metadata": {
        "id": "f714409d",
        "outputId": "510c2193-8208-4631-bca4-4b4ea4fe90a3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'my', 'each', 'have', 'up', \"isn't\", 'because', 'such', \"shouldn't\", 'why', 'or', 'his', 'him', 'do', 'by', 'against', 'themselves', 'o', 'theirs', 'above', 'has', 'hers', 'who', 'its', 'did', 'over', 'be', 'there', 'aren', 'm', \"haven't\", \"wasn't\", 'both', 'through', 'wasn', 'am', 'for', 'own', \"mightn't\", 'during', 'your', 'y', 'when', 'that', 'few', 'ourselves', 'yourself', 'haven', \"that'll\", 'mightn', 'further', 'myself', 'their', \"you'd\", 'wouldn', 'as', 'was', 'me', \"aren't\", 'himself', 'the', 'under', 'll', \"hasn't\", \"don't\", 'yourselves', 'herself', 'should', 'itself', 'whom', 'ma', 'is', 'in', 'it', \"it's\", 'you', 'isn', 'to', 'mustn', 'at', 'ain', 'where', 'off', 'needn', 'ours', 'any', 'after', 'most', 'what', 'only', 'had', 'these', 'which', 'will', \"you're\", 'yours', 'her', 'then', 'other', 'they', 'down', 'd', 'nor', 'couldn', \"shan't\", 'but', 'again', \"couldn't\", 'on', 'a', \"she's\", 'now', 'once', 'until', \"doesn't\", 'hadn', 'more', \"mustn't\", \"hadn't\", 'hasn', 'are', \"won't\", 'out', 'no', 'all', 'just', 'while', 'were', 'this', 'being', 'shan', 'having', 'doesn', 'before', 'he', 'we', 'won', 'how', 'about', 'so', 'if', 'same', \"needn't\", 'and', 'them', 'does', 'doing', \"you've\", 'can', 'between', \"weren't\", 'from', 'some', \"wouldn't\", \"should've\", 'than', 'weren', 'those', 've', 'with', 'not', 's', 't', 'she', 'i', 'here', 'shouldn', \"you'll\", 're', 'below', 'too', 'didn', 'very', 'of', 'our', 'been', \"didn't\", 'don', 'an', 'into'}\n",
            "***********************************\n",
            "tasti\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     C:\\Users\\nithy\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "#This imports the NLTK library, which is a powerful tool for natural language processing tasks.\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "# import regular expression\n",
        "import re\n",
        "import string\n",
        "#This imports the stopwords corpus from NLTK, which was downloaded earlier. It contains common stopwords in English.\n",
        "from nltk.corpus import stopwords\n",
        "#This imports the Porter Stemmer algorithm from NLTK, which is used for stemming words (reducing them to their root or base form).\n",
        "from nltk.stem import PorterStemmer\n",
        "#NLTK provides WordNetLemmatizer class which is a thin wrapper around the wordnet corpus. This class uses morphy() function to the WordNet CorpusReader class to find a lemma.\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "#These stopwords are commonly occurring words in English that are often filtered out during text preprocessing tasks.\n",
        "stop = set(stopwords.words('english'))\n",
        "\n",
        "#SnowballStemmer\n",
        "sno = nltk.stem.SnowballStemmer('english')\n",
        "\n",
        "#This defines a function named cleanhtml that takes a sentence as input.\n",
        "def cleanhtml(sentence):\n",
        "    cleanr = re.compile('<.*?')\n",
        "    cleantext = re.sub(cleanr,' ',sentence)\n",
        "    return cleantext\n",
        "# | stands for logical OR and a sentence having ?,! etc will be replaced by space\n",
        "#Defining cleanupnc Function:\n",
        "#This defines a function named cleanupnc that takes a sentence as input.\n",
        "#This line uses re.sub() to remove specific punctuation characters such as ?, !, ', \", and # from the input sentence.\n",
        "#This line further removes additional punctuation characters such as ., ,, ), (, |, and / from the cleaned text.\n",
        "#This returns the cleaned text with punctuation removed.\n",
        "def cleanupnc(sentence):\n",
        "    cleaned = re.sub(r'[?|!|\\'|\"|#]',r'',sentence)\n",
        "    cleaned = re.sub(r'[.|,|)|(|\\|/]',r' ',cleaned)\n",
        "    return cleaned\n",
        "print(stop)\n",
        "print('***********************************')\n",
        "print(sno.stem('tasty'))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "544cedfc",
      "metadata": {
        "id": "544cedfc"
      },
      "source": [
        "# Bi-Grams and n-Grams"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "40de902b",
      "metadata": {
        "id": "40de902b",
        "outputId": "efef4708-8362-433a-e107-763d52cfdd14"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Most Common Positive Words : [(b'like', 139150), (b'tast', 128631), (b'good', 112216), (b'flavor', 109473), (b'love', 107034), (b'use', 103627), (b'great', 102818), (b'product', 99504), (b'one', 95360), (b'tri', 86237), (b'tea', 83824), (b'coffe', 78610), (b'make', 74835), (b'get', 71962), (b'food', 64752), (b'amazon', 57832), (b'would', 55297), (b'time', 55225), (b'buy', 53903), (b'realli', 52569)]\n",
            "Most Common negative Words : [(b'tast', 34489), (b'like', 32284), (b'product', 29504), (b'one', 20420), (b'flavor', 19561), (b'would', 17901), (b'tri', 17676), (b'use', 15275), (b'good', 14977), (b'coffe', 14677), (b'get', 13758), (b'buy', 13690), (b'order', 12846), (b'food', 12742), (b'dont', 11683), (b'tea', 11657), (b'amazon', 11258), (b'even', 10983), (b'box', 10841), (b'make', 9816)]\n"
          ]
        }
      ],
      "source": [
        "freq_dist_positive=nltk.FreqDist(all_positive_words)\n",
        "freq_dist_negative=nltk.FreqDist(all_negative_words)\n",
        "print(\"Most Common Positive Words :\",freq_dist_positive.most_common(20))\n",
        "print(\"Most Common negative Words :\",freq_dist_negative.most_common(20))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "99f335c8",
      "metadata": {
        "id": "99f335c8"
      },
      "outputs": [],
      "source": [
        "count_vect = CountVectorizer(ngram_range=(1,2) )\n",
        "final_bigram_counts = count_vect.fit_transform(final['Text'].values)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7e2deb43",
      "metadata": {
        "id": "7e2deb43",
        "outputId": "0143617d-5bea-4f4b-a605-722a3131af95"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(364171, 2910192)"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "final_bigram_counts.get_shape()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2008897a",
      "metadata": {
        "id": "2008897a"
      },
      "source": [
        "# TF-IDF"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d001c9de",
      "metadata": {
        "id": "d001c9de"
      },
      "outputs": [],
      "source": [
        "tf_idf_vect = TfidfVectorizer(ngram_range=(1,2))\n",
        "final_tf_idf = tf_idf_vect.fit_transform(final['Text'].values)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6ba48e26",
      "metadata": {
        "id": "6ba48e26",
        "outputId": "8e1bad56-8251-4cc5-808c-390b591f0657"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(364171, 2910192)"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "final_tf_idf.get_shape()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3b52fce7",
      "metadata": {
        "id": "3b52fce7",
        "outputId": "99dc670a-02d5-4720-e9f7-e09dda6068c6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "2910192"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "features = tf_idf_vect.get_feature_names_out()\n",
        "len(features)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7fedef32",
      "metadata": {
        "id": "7fedef32",
        "outputId": "32d6f9a4-a4b4-4639-8431-04ef89a636a4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array(['ales until', 'ales ve', 'ales would', 'ales you', 'alessandra',\n",
              "       'alessandra ambrosia', 'alessi', 'alessi added', 'alessi also',\n",
              "       'alessi and'], dtype=object)"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "features[100000 : 100010]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6cdf0822",
      "metadata": {
        "id": "6cdf0822",
        "outputId": "25f7334d-1881-495c-de60-4410f63b5015"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0. 0. 0. ... 0. 0. 0.]\n"
          ]
        }
      ],
      "source": [
        "print(final_tf_idf[3,:].toarray()[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7d120a04",
      "metadata": {
        "id": "7d120a04"
      },
      "outputs": [],
      "source": [
        "def top_tfidf_feats(row,features,top_n=25):\n",
        "    ''' Get top n tfidf values in row and return them with their correspond'''\n",
        "    topn_ids = np.argsort(row)[::-1][:top_n]\n",
        "    top_feats = [(features[i], row[i])  for i in topn_ids]\n",
        "    df = pd.DataFrame(top_feats)\n",
        "    df.columns = ['feature','tfidf']\n",
        "    return df\n",
        "\n",
        "top_tfidf = top_tfidf_feats(final_tf_idf[1,:].toarray()[0],features,25)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4f43ddf6",
      "metadata": {
        "id": "4f43ddf6",
        "outputId": "f237a1ce-2b3a-4bbd-bace-3114b827a9a6"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>feature</th>\n",
              "      <th>tfidf</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>sendak books</td>\n",
              "      <td>0.173437</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>rosie movie</td>\n",
              "      <td>0.173437</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>paperbacks seem</td>\n",
              "      <td>0.173437</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>cover version</td>\n",
              "      <td>0.173437</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>these sendak</td>\n",
              "      <td>0.173437</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>the paperbacks</td>\n",
              "      <td>0.173437</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>pages open</td>\n",
              "      <td>0.173437</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>really rosie</td>\n",
              "      <td>0.168074</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>incorporates them</td>\n",
              "      <td>0.168074</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>paperbacks</td>\n",
              "      <td>0.168074</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>however miss</td>\n",
              "      <td>0.164269</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>hard cover</td>\n",
              "      <td>0.164269</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>seem kind</td>\n",
              "      <td>0.161317</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>up reading</td>\n",
              "      <td>0.156867</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>that incorporates</td>\n",
              "      <td>0.155100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>the pages</td>\n",
              "      <td>0.149737</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>sendak</td>\n",
              "      <td>0.149737</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>rosie</td>\n",
              "      <td>0.146786</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>of flimsy</td>\n",
              "      <td>0.146786</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>two hands</td>\n",
              "      <td>0.145130</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>movie that</td>\n",
              "      <td>0.144374</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>reading these</td>\n",
              "      <td>0.137184</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>too do</td>\n",
              "      <td>0.134491</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>incorporates</td>\n",
              "      <td>0.134147</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>flimsy and</td>\n",
              "      <td>0.132254</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              feature     tfidf\n",
              "0        sendak books  0.173437\n",
              "1         rosie movie  0.173437\n",
              "2     paperbacks seem  0.173437\n",
              "3       cover version  0.173437\n",
              "4        these sendak  0.173437\n",
              "5      the paperbacks  0.173437\n",
              "6          pages open  0.173437\n",
              "7        really rosie  0.168074\n",
              "8   incorporates them  0.168074\n",
              "9          paperbacks  0.168074\n",
              "10       however miss  0.164269\n",
              "11         hard cover  0.164269\n",
              "12          seem kind  0.161317\n",
              "13         up reading  0.156867\n",
              "14  that incorporates  0.155100\n",
              "15          the pages  0.149737\n",
              "16             sendak  0.149737\n",
              "17              rosie  0.146786\n",
              "18          of flimsy  0.146786\n",
              "19          two hands  0.145130\n",
              "20         movie that  0.144374\n",
              "21      reading these  0.137184\n",
              "22             too do  0.134491\n",
              "23       incorporates  0.134147\n",
              "24         flimsy and  0.132254"
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "top_tfidf"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}